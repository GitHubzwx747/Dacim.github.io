---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

æ›¾å¾·ç‚‰ï¼Œåšå£«ï¼Œæ•™æˆï¼Œåšå£«ç”Ÿå¯¼å¸ˆ/ç¡•å£«ç”Ÿå¯¼å¸ˆã€‚æ›¾åœ¨ç›¸å…³é¢†åŸŸå‘è¡¨è®ºæ–‡100ä½™ç¯‡ï¼ŒåŒ…æ‹¬IEEEç­‰è‘—åä¼šåˆŠï¼Œå¦‚IEEE Trans. Neural Networks and Learning Systems, IEEE Trans. Image Processing, IEEE Geoscience and Remote Sensing Letters, IEEE Signal Processing Letters ï¼ŒåŠICMLï¼ŒAAAIï¼ŒIJCAIï¼ŒICCVï¼ŒCVPRï¼ŒICASSPç­‰è§†é¢‘å¤„ç†æ¨¡å¼è¯†åˆ«é¡¶çº§ä¼šè®®ã€‚ä¸»æŒå›½å®¶åŠçœéƒ¨çº§é¡¹ç›®å¤šé¡¹ï¼šåŒ…æ‹¬å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é¡¹ç›®3é¡¹ï¼Œä¸­å›½åšå£«ååŸºé‡‘é¡¹ç›®ç­‰ï¼›å‚ä¸å›½å®¶åŠçœéƒ¨çº§é¡¹ç›®å¤šé¡¹ç­‰ï¼›ä¸»æŒæ¨ªå‘é¡¹ç›®å¤šé¡¹ã€‚

å­¦æœ¯ä¹‰åŠ¡å·¥ä½œï¼šACMä¼šå‘˜ï¼ŒCCFä¼šå‘˜ï¼ŒIEEEä¼šå‘˜ï¼Œå‚ä¸NSFCè¯„å®¡ç­‰ï¼›å¹¶å‚ä¸å¤šä¸ªå›½é™…æœŸåˆŠå®¡ç¨¿ï¼ŒåŒ…æ‹¬IEEE TIPï¼ŒIEEE ITSï¼ŒIEEE TNNLSï¼ŒIEEE TIIï¼Œ IEEE TEIï¼ŒIEEE TMMï¼ŒIEEE SMCbï¼ŒNeural Networksï¼ŒNeurocomputingç­‰ã€‚
## å·¥ä½œç»å†

- **2022.02 â€“ è‡³ä»Š**ã€€åå—ç†å·¥å¤§å­¦ï¼Œç”µå­ä¸ä¿¡æ¯å­¦é™¢ï¼Œæ•™æˆ  
- **2018.09 â€“ 2021.01**ã€€åå—ç†å·¥å¤§å­¦ï¼Œæ•°å­¦å­¦é™¢ä¿¡æ¯ä¸è®¡ç®—ç§‘å­¦ç³»ï¼Œæ•™æˆ  
- **2018.11 â€“ 2019.11**ã€€å“¥ä¼¦æ¯”äºšå¤§å­¦æ•°æ®ç§‘å­¦å­¦é™¢ï¼Œè®¿é—®å­¦è€…ï¼ˆå›½å®¶å…¬æ´¾ CSCï¼‰  
- **2018.08 â€“ 2018.09**ã€€å¥¥å¢å¤§å­¦ CMVSï¼Œç ”ç©¶ç§‘å­¦å®¶ï¼ˆè®¿é—®å­¦è€…ï¼‰  
- **2017.07 â€“ 2017.09**ã€€å“¥ä¼¦æ¯”äºšå¤§å­¦æ•°æ®ç§‘å­¦å­¦é™¢ï¼Œè®¿é—®å­¦è€…  
- **2016.07 â€“ 2018.08**ã€€åå—ç†å·¥å¤§å­¦ï¼Œæ•°å­¦å­¦é™¢ä¿¡æ¯ä¸è®¡ç®—ç§‘å­¦ç³»ï¼Œå‰¯æ•™æˆ  
- **2013.04 â€“ 2016.07**ã€€å¦é—¨å¤§å­¦ï¼Œä¿¡æ¯ç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢ï¼Œå‰¯æ•™æˆ  
- **2010.02 â€“ 2013.03**ã€€åå—ç†å·¥å¤§å­¦ï¼Œç”µå­ä¸ä¿¡æ¯å­¦é™¢ï¼Œåšå£«åï¼ˆ2011.09 è·å‰¯ç ”ç©¶å‘˜/å‰¯é«˜èµ„æ ¼ï¼‰

## æ•™è‚²ç»å†

- **2005.09 â€“ 2009.12**ã€€åå—ç†å·¥å¤§å­¦ï¼Œä¿¡å·ä¸ä¿¡æ¯å¤„ç†ï¼Œåšå£«ç ”ç©¶ç”Ÿ  
  ï¼ˆç ”ç©¶æ–¹å‘ï¼šè¿­ä»£å­¦ä¹ ç†è®ºã€æ§åˆ¶ç†è®ºã€ä¿¡å·ä¸ä¿¡æ¯å¤„ç†ç­‰ï¼‰  
- **2003.09 â€“ 2005.07**ã€€åå—ç†å·¥å¤§å­¦ï¼Œåº”ç”¨æ•°å­¦ï¼Œç¡•å£«ç ”ç©¶ç”Ÿ  
  ï¼ˆç ”ç©¶æ–¹å‘ï¼šéçº¿æ€§å‘å±•æ–¹ç¨‹åŠåº”ç”¨ï¼‰  
- **2005.07 â€“ 2005.09**ã€€ä¸­å±±å¤§å­¦ï¼Œå…¨å›½æ•°å­¦æš‘æœŸå­¦ä¹ ç­ï¼Œéå­¦å†åŸ¹è®­  
  ï¼ˆå­¦ä¹ ä¸»é¢˜ï¼šåå¾®åˆ†æ–¹ç¨‹ä¸å¾®åˆ†å‡ ä½•ï¼‰  
- **1999.09 â€“ 2003.07**ã€€åå—ç†å·¥å¤§å­¦ï¼Œæ•°å­¦ä¸åº”ç”¨æ•°å­¦ï¼Œæœ¬ç§‘ / å­¦å£«

## ç ”ç©¶é¢†åŸŸ

- **ä¸»è¦é¢†åŸŸ**ï¼šå›¾åƒå¤„ç†ä¸æ¨¡å¼è¯†åˆ«ã€å¤§æ•°æ®å¤„ç†ä¸åˆ†æã€ï¼ˆç»Ÿè®¡ï¼‰æœºå™¨å­¦ä¹ ã€åå¾®åˆ†æ–¹ç¨‹åº”ç”¨  
- **å…¶ä»–æ¶‰åŠé¢†åŸŸ**ï¼šå·¥ç¨‹æ•°å­¦å»ºæ¨¡ã€äººå·¥æ™ºèƒ½ä¸æ„ŸçŸ¥æ¨ç†ã€æœ€ä¼˜åŒ–ç†è®ºåŠåº”ç”¨ã€æƒ…æ„Ÿè®¡ç®—ã€é€šä¿¡ï¼ç”Ÿç‰©åŒ»å­¦ä¿¡æ¯å¤„ç†ã€ç‰©è”ç½‘åŠè½¯ä»¶å®šä¹‰ç½‘ç»œç­‰

# ğŸ”¥ News
- *2026.1*: Our paper about *Diffusion Bridge Variational Inference for Deep Gaussian Processes* is accepted to International Conference on Learning Representations (ICLR).
- *2026.1*: Our paper about *Don't Forget Its Variance! The Minimum Path Variance Principle for Accurate and Stable Score-Based Density Ratio* is accepted to  International Conference on Learning Representations (ICLR).
- *2025.10*: Our paper about *diffusion informer for time series modeling* is accepted to Expert Systems With Applications (ESWA).
- *2025.10*: Our paper about *wavelet diffusion for time series modeling* is accepted to IEEE TIM.
- *2025.09*: Our paper about *diffusion modeling acceleration* is accepted to NeurIPS 2025.
- *2025.09*: Our paper about *normalizing flow* is accepted to Pattern Recognition (PR).
- *2025.08*: Our paper about *diffusion models for low-level CV* is accepted to Neurocomputing.
- *2025.10*: Our paper about *time series modeling* is accepted to IEEE Transactions on Instrumentation & Measurement (TIM).
- *2025.05*: Our paper about *stable & efficient density ratio estimation* is accepted to ICML 2025.
- *2024.06*: Our paper about *Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference* is accepted to ICML 2024. 
- *2022.02*: Our paper about *efficient continuous normalizing flow* is accepted to CVPR 2022. 

# ğŸ“ Publications 
## Deep Generative Modeling

<div class='paper-box'><div class='paper-box-image'><img src='images/evodiff.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**EVODiff: Entropy-aware Variance Optimized Diffusion Inference**](https://openreview.net/forum?id=rKASv92Myl), Shigui Li, **`Wei Chen`**, Delu Zeng*

**NeurIPS 2025** \| [**Paper**](https://openreview.net/pdf?id=rKASv92Myl) \| [**Code**](https://github.com/ShiguiLi/EVODiff) \| [**News&#127881;**](https://mp.weixin.qq.com/s/mviiMgexMub_os4oSIdwiQ)

- Introduces an information-theoretic view: successful denoising reduces conditional entropy in reverse transitions.
- Proposes EVODiff, a reference-free diffusion inference framework that optimizes conditional variance to reduce transition and reconstruction errors, improving sample quality and reducing inference cost.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/eiw_flow.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**Entropy-informed weighting channel normalizing flow for deep generative models**](https://doi.org/10.1016/j.patcog.2025.112442), **`Wei Chen`**#, Shian Du#, Shigui Li#, Delu Zeng*, John Paisley

**Pattern Recognition (PR) 2025** \| [**Paper**](https://doi.org/10.1016/j.patcog.2025.112442) \| [**Code**](https://github.com/ShianDu/EIW-Flow)

- Proposes Entropy-Informed Weighting Channel Normalizing Flow (EIW-Flow), enhancing multi-scale normalizing flows with a regularized, feature-dependent operation that generates channel-wise weights and shuffles latent variables before splitting.
- Empirically achieves state-of-the-art density estimation and competitive sample quality with minimal computational overhead on multiple benchmarks.
</div>
</div>


<div class='paper-box'>
<div class='paper-box-image'><img src='images/reciprocalla.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**ReciprocalLA-LLIE: Low-light image enhancement with luminance-aware reciprocal diffusion process**](https://doi.org/10.1016/j.neucom.2025.131438), Zhiqi Lin, **`Wei Chen`**, Jian Xu, Delu Zeng*, Min Chen

**Neurocomputing 2025** \| [**Paper**](https://doi.org/10.1016/j.neucom.2025.131438)

- Proposes a reciprocal diffusion process (between low-light and well-exposed images) within a score-based DDPM framework via drift adjustment, with the low-light image as an endpoint state rather than only a conditional input.
- Introduces a Luminance Adjustment Block for robust global luminance control, suppressing noise and preserving details.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/toflow.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**To-Flow: Efficient Continuous Normalizing Flows with Temporal Optimization Adjoint with Moving Speed**](https://arxiv.org/abs/2203.10335), Shian Du#, Yihong Luo#, **`Wei Chen`**#, Jian Xu, Delu Zeng*

**CVPR 2022** \| [**Paper**](https://arxiv.org/abs/2203.10335) \| [**Code**](https://github.com/ShianDu/TO-FLOW)

- Continuous normalizing flows (CNFs) via neural ODEs are costly to train on large datasets; To-Flow proposes *temporal optimization* by alternately optimizing network weights and evolutionary time (coordinate descent) with temporal regularization for stability.
- **Key result**: accelerates flow training by about 20% while maintaining performance.
</div>
</div>


## Density Ratio Estimation

<div class='paper-box'><div class='paper-box-image'><img src='images/d3re.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**Dequantified Diffusion-SchrÃ¶dinger Bridge for Density Ratio Estimation**](https://openreview.net/forum?id=zvyHCOcwsw), **`Wei Chen`**, Shigui Li, Jiacheng Li, Junmei Yang, John Paisley, Delu Zeng*

**ICML 2025** \| [**Paper**](https://openreview.net/forum?id=zvyHCOcwsw) \| [**Code**](https://github.com/Hoemr/Dequantified-Diffusion-Bridge-Density-Ratio-Estimation.git)

- Proposes D3RE, a unified framework for robust and stable density ratio estimation under distribution mismatch (density-chasm / support-chasm), addressing instability from divergent time scores near boundaries.
- Introduces dequantified diffusion bridge interpolant (DDBI) for support expansion and stabilized time scores; further extends to dequantified SchrÃ¶dinger bridge interpolant (DSBI) to enhance accuracy and efficiency.
</div>
</div>


## Time Series Forecast

<div class='paper-box'><div class='paper-box-image'><img src='images/deepara.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**DeepAR-Attention probabilistic prediction for stock price series**](https://doi.org/10.1007/s00521-024-09916-3), Jiacheng Li, **`Wei Chen`**, Zhiheng Zhou, Junmei Yang, Delu Zeng*

**Neural Computing and Applications 2024** \| [**Paper**](https://doi.org/10.1007/s00521-024-09916-3)

- Proposes a DeepAR-Attention probabilistic forecasting approach for stock price series.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/ODE_LSTM.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**Neural ordinary differential equation networks for fintech applications using Internet of Things**](https://doi.org/10.1109/JIOT.2024.3376748), Jiacheng Li, **`Wei Chen`**, Yican Liu, Junmei Yang, Delu Zeng*, Zhiheng Zhou

**IEEE Internet of Things Journal (IoTJ) 2024** \| [**Paper**](https://doi.org/10.1109/JIOT.2024.3376748) 

- Develops neural ODE network approaches for fintech applications in IoT settings.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/evolvinformer.png' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**Integrating Ordinary Differential Equations with Sparse Attention for Power Load Forecasting**](https://doi.org/10.1109/TIM.2025.3581667), Jiacheng Li, **`Wei Chen`**, Yican Liu, Junmei Yang, Zhiheng Zhou, Delu Zeng*

**IEEE Transactions on Instrumentation and Measurement (T-IM) 2025** \| [**Paper**](https://doi.org/10.1109/TIM.2025.3581667)

- Proposes EvolvInformer: integrates an ODE solver into a ProbSparse self-attention decoder to model continuous-time hidden state dynamics for nonstationary long-sequence load forecasting.
- Reports a 29.7% MSE reduction versus state-of-the-art baselines while preserving logarithmic memory complexity.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><img src='images/diffinformer.jpg' alt="sym" width="100%"></div>
<div class='paper-box-text' markdown="1">

[**Diffinformer: Diffusion Informer model for long sequence time-series forecasting**](https://doi.org/10.1016/j.eswa.2025.129944), Jiacheng Li, **`Wei Chen`**, Yican Liu, Junmei Yang, Zhiheng Zhou, Delu Zeng*

**Expert Systems with Applications (ESWA) 2025** \| [**Paper**](https://doi.org/10.1016/j.eswa.2025.129944)

- Proposes Diffinformer: combines conditional diffusion models with Informerâ€™s ProbSparse attention distilling mechanism, incorporating diffusion outputs into the decoder to better capture long-range dependencies.
- Demonstrates consistent improvements over corresponding baselines across five large-scale datasets under limited computational resources.
</div>
</div>



# ğŸ– Honors and Awards


# ğŸ“– Educations
 

# ğŸ’¬ Invited Talks


# ğŸ’» Internships
  - 
